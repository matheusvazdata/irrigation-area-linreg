# Irrigation Linear Regression Project

<p align="left">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg?style=for-the-badge&logo=python" />
  <img src="https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/Uvicorn-4B8BBE?style=for-the-badge&logo=uvicorn&logoColor=white" />
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white" />
  <img src="https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=plotly&logoColor=white" />
</p>

This project implements a **complete machine learning workflow** to analyze irrigation data, train a **Linear Regression model**, evaluate its performance, run residual diagnostics, and serve predictions through a **FastAPI web API**.

The goal is to predict the **Irrigated Area per Angle** based on the number of **Irrigation Hours**, enabling data-driven decision-making in agricultural water management.

## ğŸ“‚ Project Structure

```
irrigation-area-linreg/
â”œâ”€â”€ artifacts/                        # Trained model and metadata
â”‚   â”œâ”€â”€ metadata.json
â”‚   â””â”€â”€ model.joblib
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/                    # Intermediate/processed data (ignored in .gitignore)
â”‚   â””â”€â”€ raw/                          # Raw input data
â”‚       â””â”€â”€ irrigation_data.csv
â”œâ”€â”€ reports/                          # Generated plots and diagnostics
â”‚   â”œâ”€â”€ diagnostics/
â”‚   â”‚   â””â”€â”€ residuals_qqplot.png
â”‚   â””â”€â”€ figures/
â”‚       â”œâ”€â”€ scatter_hours_vs_area_per_angle.png
â”‚       â””â”€â”€ true_vs_pred.png
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ run_pipeline.py                   # End-to-end pipeline script
â””â”€â”€ src/                              # Source code
    â”œâ”€â”€ api/
    â”‚   â””â”€â”€ main.py                   # FastAPI application
    â”œâ”€â”€ config.py                     # Project configuration (paths, constants)
    â”œâ”€â”€ data_loader.py                # Load and preprocess data
    â”œâ”€â”€ eda.py                        # Exploratory Data Analysis
    â”œâ”€â”€ evaluator.py                  # Model evaluation (MSE, MAE)
    â”œâ”€â”€ residuals.py                  # Residual analysis and normality checks
    â”œâ”€â”€ tests/
    â”‚   â””â”€â”€ test_basic.py             # Basic unit test
    â”œâ”€â”€ trainer.py                    # Model training and persistence
    â””â”€â”€ utils/
        â””â”€â”€ plotting.py               # Plotting utilities
```

## âš™ï¸ Installation & Setup

### 1. Clone the repository

You can clone the repository either via **HTTPS** or **SSH**:

**HTTPS (recommended for beginners):**
```bash
git clone https://github.com/matheusvazdata/irrigation-area-linreg.git
cd irrigation-area-linreg
```

**SSH (recommended if you already configured your SSH keys with GitHub):**

```bash
git clone git@github.com:matheusvazdata/irrigation-area-linreg.git
cd irrigation-area-linreg
```

### 2. Create a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate   # Linux/Mac
# .venv\Scripts\activate    # Windows (PowerShell)
```

### 3. Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## ğŸ“Š Data

This project already includes the dataset inside the repository, located at:

```
data/raw/irrigation_data.csv
```

Columns:

* `Irrigation Hours` â€“ Number of hours of irrigation
* `Irrigated Area` â€“ Total irrigated area
* `Irrigated Area per Angle` â€“ Irrigated area distributed per irrigation angle

> No manual download is required â€” the pipeline will read this file directly.

## ğŸš€ Running the Pipeline

To execute the entire pipeline (EDA â†’ Training â†’ Evaluation â†’ Residuals):

```bash
python run_pipeline.py
```

This will:

* Generate plots in `reports/figures/`
* Train the linear regression model and save it to `artifacts/model.joblib`
* Save model metadata in `artifacts/metadata.json`
* Print evaluation metrics (MSE, MAE)
* Run residual diagnostics and save a QQ-plot in `reports/diagnostics/`

## ğŸ“ˆ Generated Reports

* **Scatter plot**: `reports/figures/scatter_hours_vs_area_per_angle.png`
* **True vs Predicted**: `reports/figures/true_vs_pred.png`
* **Residuals QQ-plot**: `reports/diagnostics/residuals_qqplot.png`

These plots allow you to visually inspect linearity, model fit, and residual normality.

## ğŸ¤– Model Serving (API)

The project includes a **FastAPI** server that exposes endpoints for real-time predictions.

### Run the API

```bash
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

API will be available at:

* Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
* Redoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Endpoints

#### Healthcheck

```http
GET /health
```

#### Model Info

```http
GET /model-info
```

Returns metadata about the trained model (equation, coefficients, test size, etc).

#### Predict (single input)

```http
POST /predict
Content-Type: application/json
{
  "irrigation_hours": 15
}
```

Response:

```json
{
  "irrigated_area_per_angle": 1000.0
}
```

#### Predict Batch (multiple inputs)

```http
POST /predict-batch
Content-Type: application/json
{
  "irrigation_hours": [1, 2, 5, 10, 15]
}
```

Response:

```json
{
  "irrigated_area_per_angle": [66.67, 133.33, 333.33, 666.67, 1000.0]
}
```

## ğŸ§ª Testing

To run the basic unit test:

```bash
pytest src/tests -q
```

## ğŸ” Key Features

* **Reproducible ML pipeline**: Data loading, EDA, training, evaluation, diagnostics
* **Persistence**: Model saved with `joblib` and metadata in JSON
* **Reports**: Plots automatically generated for interpretability
* **API ready**: Serve predictions with FastAPI
* **Extensible**: Easy to adapt for new datasets or models

## ğŸ› ï¸ Possible Improvements

* Add noise injection for more realistic datasets
* Implement polynomial regression or regularization (Ridge, Lasso)
* Add CI/CD integration (GitHub Actions)
* Containerize with Docker for deployment

## ğŸ‘¤ Author

Developed by **Francisco Matheus Vaz dos Santos**

* GitHub: [github.com/matheusvazdata](https://github.com/matheusvazdata)
* LinkedIn: [linkedin.com/in/matheusvazdata](https://www.linkedin.com/in/matheusvazdata)
* Datacamp: [datacamp.com/portfolio/matheusvazdata](https://www.datacamp.com/portfolio/matheusvazdata)